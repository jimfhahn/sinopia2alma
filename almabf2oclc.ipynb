{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Alma BIBFRAME for export to OCLC (experimental)\n",
    "\n",
    "The experimental project makes use of an [SRU query](https://na03.alma.exlibrisgroup.com/view/sru/01UPENN_INST?version=1.2&operation=searchRetrieve&recordSchema=lc_bf_instance&query=alma.title_uri=%22sinopia%22&maximum_records=50) to gather all the BF Instances from Sinopia that are found in Alma. In the code cell 3, replace the values for your region and the institution code for your institution.\n",
    "\n",
    "## Region\n",
    "``region = 'https://na03.alma.exlibrisgroup.com/'``\n",
    "\n",
    "## Institution code \n",
    "###  replace (01UPENN_INST) with your code\n",
    "``institution_code = '01UPENN_INST'``\n",
    "\n",
    "## OCLC Documentation\n",
    "[OCLC RDF structure](https://help.oclc.org/Metadata_Services/WorldShare_Collection_Manager/Data_sync_collections/Prepare_your_data/Structure_BIBFRAME_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install rdflib\n",
    "%pip install lxml\n",
    "%pip install requests\n",
    "%pip install saxoncee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SRU to get all the BF Instances in Alma\n",
    "\n",
    "import requests\n",
    "from lxml import etree\n",
    "\n",
    "region = 'na03.alma.exlibrisgroup.com'\n",
    "institution_code = '01UPENN_INST'\n",
    "url = 'https://'+region+'/view/sru/'+institution_code+'?version=1.2&operation=searchRetrieve&recordSchema=lc_bf_instance&query=alma.title_uri=%22sinopia%22&maximumRecords=50'\n",
    "response = requests.get(url)\n",
    "# print(response.text)\n",
    "\n",
    "# parse the response for the Instance URIs and collect them in a dictionary\n",
    "root = etree.fromstring(response.content)\n",
    "\n",
    "instance_dict = {}\n",
    "\n",
    "# collect all the unique instance URIs and their corresponding bf:sameAs URIs\n",
    "for record in root.iter('{http://www.loc.gov/zing/srw/}record'):\n",
    "    record_data = record.find('{http://www.loc.gov/zing/srw/}recordData')\n",
    "    if record_data is not None:\n",
    "        rdf = record_data.find('.//{http://www.w3.org/1999/02/22-rdf-syntax-ns#}RDF')\n",
    "        if rdf is not None:\n",
    "            instance = rdf.find('.//{http://id.loc.gov/ontologies/bibframe/}Instance')\n",
    "            if instance is not None:\n",
    "                instance_uri = instance.get('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}about')\n",
    "                if instance_uri:\n",
    "                    same_as = instance.find('.//{http://id.loc.gov/ontologies/bibframe/}sameAs')\n",
    "                    if same_as is not None:\n",
    "                        same_as_uri = same_as.get('{http://www.w3.org/1999/02/22-rdf-syntax-ns#}about')\n",
    "                        if same_as_uri:\n",
    "                            instance_dict[instance_uri] = same_as_uri\n",
    "                        else:\n",
    "                            print(f\"No 'about' attribute found in sameAs element for instance {instance_uri}.\")\n",
    "                    else:\n",
    "                        print(f\"No sameAs element found for instance {instance_uri}.\")\n",
    "                else:\n",
    "                    print(\"No 'about' attribute found in Instance element.\")\n",
    "            else:\n",
    "                print(\"No Instance element found in RDF element.\")\n",
    "        else:\n",
    "            print(\"No RDF element found in recordData element.\")\n",
    "    else:\n",
    "        print(\"No recordData element found in record element.\")\n",
    "\n",
    "print(\"Collected instance URIs and their corresponding sameAs URIs:\", instance_dict)\n",
    "print(f\"Total instances collected: {len(instance_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the Instance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as ET\n",
    "from marc_xml.lc_bfxml_work import lc_bfxml_work, remove_last_line\n",
    "from marc_xml.lc_bfxml_instance import lc_bfxml_instance, remove_rdf_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import etree as ET\n",
    "from lxml.etree import QName\n",
    "\n",
    "def rdf2marcxml(instance_dict):\n",
    "    # Ensure the export directory exists\n",
    "    export_dir = 'oclc_export'\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "    \n",
    "    for instance_uri, same_as_uri in instance_dict.items():\n",
    "        # Quality check the file\n",
    "        \n",
    "        lc_bfxml_work(instance_uri)  \n",
    "        remove_last_line() \n",
    "        lc_bfxml_instance(instance_uri) \n",
    "        remove_rdf_header() \n",
    "        \n",
    "        # Combine the two files, work first\n",
    "        with open(\"bfxml_work.xml\", \"r\") as work_file:\n",
    "            work = work_file.read()\n",
    "        with open(\"lc_bfxml_instance.xml\", \"r\") as instance_file:\n",
    "            instance = instance_file.read()\n",
    "        \n",
    "        combined_content = work + instance\n",
    "\n",
    "        # Save as a file\n",
    "        combined_file_path = \"LoC_Work_Instance.xml\"\n",
    "        with open(combined_file_path, \"w\") as combined_file:\n",
    "            combined_file.write(combined_content)\n",
    "\n",
    "        # Add the sinopiabf and owl namespaces to the combined file\n",
    "        with open(combined_file_path, \"r\") as file:\n",
    "            filedata = file.read()\n",
    "        filedata = filedata.replace('<rdf:RDF', '<rdf:RDF xmlns:sinopiabf=\"http://sinopia.io/vocabulary/bf/\" xmlns:owl=\"http://www.w3.org/2002/07/owl#\"')\n",
    "        with open(combined_file_path, \"w\") as file:\n",
    "            file.write(filedata)\n",
    "\n",
    "        # Parse the combined XML\n",
    "        dom = ET.parse(combined_file_path)\n",
    "        root = dom.getroot()\n",
    "\n",
    "        # Define namespaces\n",
    "        namespaces = {\n",
    "            'rdf': \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\",\n",
    "            'bf': \"http://id.loc.gov/ontologies/bibframe/\",\n",
    "            'owl': \"http://www.w3.org/2002/07/owl#\"\n",
    "        }\n",
    "\n",
    "        # Insert the sameAs link as <owl:SameAs rdf:resource=\"uri_value\"/>\n",
    "        owl_same_as = ET.Element(\"{http://www.w3.org/2002/07/owl#}SameAs\", attrib={QName(namespaces['rdf'], \"resource\"): same_as_uri})\n",
    "        instance_element = root.find('.//bf:Instance[@rdf:about=\"' + instance_uri + '\"]', namespaces=namespaces)\n",
    "        if instance_element is not None:\n",
    "            instance_element.append(owl_same_as)\n",
    "        else:\n",
    "            print(f\"Instance element not found for URI: {instance_uri}\")\n",
    "\n",
    "        # Extract the unique ID from the Sinopia URI\n",
    "        unique_id = instance_uri.split('/')[-1]\n",
    "\n",
    "        # Save the updated XML with the unique ID as the file name\n",
    "        updated_file_path = os.path.join(export_dir, f\"{unique_id}.xml\")\n",
    "        with open(updated_file_path, \"wb\") as f:\n",
    "            f.write(ET.tostring(root, pretty_print=True, encoding=\"utf-8\"))\n",
    "\n",
    "        # Apply \"pre-transform-normalize.xsl\" for normalization\n",
    "        xslt = ET.parse(\"marc_xml/xsl/pre-transform-normalize.xsl\")\n",
    "        transform = ET.XSLT(xslt)\n",
    "        newdom = transform(dom)\n",
    "        \n",
    "        normalized_file_path = os.path.join(export_dir, f\"{unique_id}_normalized.rdf\")\n",
    "        with open(normalized_file_path, \"wb\") as f:\n",
    "            f.write(ET.tostring(newdom, pretty_print=True, encoding=\"utf-8\"))\n",
    "\n",
    "        print(f\"Processed and saved: {normalized_file_path}\")\n",
    "\n",
    "# Expected data model\n",
    "# instance_dict = {\n",
    "#     \"https://api.stage.sinopia.io/resource/4ac80e0a-d28d-458d-bd7f-5f808023af8d\": \"https://na03.alma.exlibrisgroup.com/bf/instances/9979461923903681?institute=01UPENN_INST\",\n",
    "#     \"https://api.stage.sinopia.io/resource/6dff794b-965b-424f-abcb-cbe16ab9e260\": \"https://na03.alma.exlibrisgroup.com/bf/instances/9979515924303681?institute=01UPENN_INST\"\n",
    "# }\n",
    "rdf2marcxml(instance_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import etree\n",
    "\n",
    "def apply_final_xslt(instance_dict):\n",
    "    # Ensure the export directory exists\n",
    "    export_dir = 'oclc_export'\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "    # Load the XSLT file\n",
    "    xslt_file = 'xsl/rdf2oclc.xsl'\n",
    "    xslt_doc = etree.parse(xslt_file)\n",
    "    transform = etree.XSLT(xslt_doc)\n",
    "\n",
    "    for instance_uri in instance_dict.keys():\n",
    "        # Extract the unique ID from the Sinopia URI\n",
    "        unique_id = instance_uri.split('/')[-1]\n",
    "\n",
    "        # Load the input RDF/XML content\n",
    "        input_file = os.path.join(export_dir, f\"{unique_id}_normalized.rdf\")\n",
    "        with open(input_file, 'r') as f:\n",
    "            input_xml = f.read()\n",
    "\n",
    "        # Parse the input XML\n",
    "        input_doc = etree.fromstring(input_xml)\n",
    "\n",
    "        # Apply the transformation\n",
    "        result_doc = transform(input_doc)\n",
    "\n",
    "        # Save the transformed XML to a file with the unique ID\n",
    "        output_file = os.path.join(export_dir, f\"{unique_id}_final.rdf\")\n",
    "        with open(output_file, 'wb') as f:\n",
    "            f.write(etree.tostring(result_doc, pretty_print=True, encoding='UTF-8'))\n",
    "\n",
    "        # Print the transformed XML\n",
    "        print(f\"Transformed XML for {unique_id}:\")\n",
    "        print(etree.tostring(result_doc, pretty_print=True, encoding='UTF-8').decode('UTF-8'))\n",
    "\n",
    "# Expected data model \n",
    "# instance_dict = {\n",
    "#     \"https://api.stage.sinopia.io/resource/4ac80e0a-d28d-458d-bd7f-5f808023af8d\": \"https://na03.alma.exlibrisgroup.com/bf/instances/9979461923903681?institute=01UPENN_INST\",\n",
    "#     \"https://api.stage.sinopia.io/resource/6dff794b-965b-424f-abcb-cbe16ab9e260\": \"https://na03.alma.exlibrisgroup.com/bf/instances/9979515924303681?institute=01UPENN_INST\"\n",
    "# }\n",
    "apply_final_xslt(instance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
